---
title: "Practical Machine learning"
author: "grvn12"
date: "Sunday, August 23, 2015"
output: html_document
---
#Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

#Data
The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment. 

#selecting the prediction algorithm
1. Loading the data into memoery from website and create training and testing sets. Remove columns wiht no or little data 

```{r,echo=TRUE}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

## Load all required libraries.

```{r,echo=TRUE}
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(gbm)
library(doParallel)
library(survival)
library(splines)
library(plyr)
```
## Load the data and do the cleaning

```{r,echo=TRUE}
training <- training[, 6:dim(training)[2]]

treshold <- dim(training)[1] * 0.95
#Remove columns with more than 95% of NA or "" values
ClearCols <- !apply(training, 2, function(x) sum(is.na(x)) > treshold  || sum(x=="") > treshold)

training <- training[, ClearCols]

UnclearCols <- nearZeroVar(training, saveMetrics = TRUE)

training <- training[, UnclearCols$nzv==FALSE]

training$classe = factor(training$classe)

#Partition rows into training and crossvalidation
inTrain <- createDataPartition(training$classe, p = 0.6)[[1]]
crossv <- training[-inTrain,]
training <- training[ inTrain,]
inTrain <- createDataPartition(crossv$classe, p = 0.75)[[1]]
crossv_test <- crossv[ -inTrain,]
crossv <- crossv[inTrain,]


testing <- testing[, 6:dim(testing)[2]]
testing <- testing[, ClearCols]
testing$classe <- NA
testing <- testing[, UnclearCols$nzv==FALSE]
```

2. Try for 3 methods Random Forrest, Gradient boosted model and Linear discriminant analysis

```{r,echo=TRUE}
#mod1 <- train(classe ~ ., data=training, method="rf")
#mod2 <- train(classe ~ ., data=training, method="gbm")
#mod3 <- train(classe ~ ., data=training, method="lda")

#pred1 <- predict(mod1, crossv)
#pred2 <- predict(mod2, crossv)
#pred3 <- predict(mod3, crossv)

#confusionMatrix(pred1, crossv$classe)
#confusionMatrix(pred2, crossv$classe)
#confusionMatrix(pred3, crossv$classe)

#Create Combination Model

#predDF <- data.frame(pred1, pred2, pred3, classe=crossv$classe)

#combModFit <- train(classe ~ ., method="rf", data=predDF)
#in-sample error
#combPredIn <- predict(combModFit, predDF)
#confusionMatrix(combPredIn, predDF$classe)



#out-of-sample error
#pred1 <- predict(mod1, crossv_test)
#pred3 <- predict(mod3, crossv_test)
#accuracy <- sum(pred1 == crossv_test$classe) / length(pred1)
```

Based on results, the Random Forest prediction was far better than either the GBM or lsa models. The RF model will be used as the sole prediction model. The confusion matrix created gives an accuracy of 99.6%. This is excellent.

As a double check the out of sample error was calculated. This model achieved 99.7449 % accuracy on the validation set.

Fine Tuning

Assess Number of relevant variables
```{r,echo=TRUE}
#varImpRF <- train(classe ~ ., data = training, method = "rf")
#varImpObj <- varImp(varImpRF)
# Top 40 plot
#plot(varImpObj, main = "Importance of Top 40 Variables", top = 40)

# Top 25 plot
#plot(varImpObj, main = "Importance of Top 25 Variables", top = 25)
```
The Random Forest method worked very well.

The Confusion Matrix achieved 99.6% accuracy. The Out of Sample Error achieved 99.7449 %.

This model will be used for the final calculations.

The logic behind using the random forest method as the predictor rather than other methods or a combination of various methods is:

Random forests are suitable when to handling a large number of inputs, especially when the interactions between variables are unknown.
Random forest's built in cross-validation component that gives an unbiased estimate of the forest's out-of-sample (or bag) (OOB) error rate.
A Random forest can handle unscaled variables and categorical variables. This is more forgiving with the cleaning of the data.
